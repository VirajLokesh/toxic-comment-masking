# ğŸ›¡ï¸ Toxic Comment Detection & Automatic Masking System  
### Machine Learning & Natural Language Processing Project

---

## ğŸ“Œ Project Overview

Social media platforms such as Instagram, YouTube, and Twitter receive millions of comments every day. While many comments are positive and supportive, a large number of them are abusive, hateful, and toxic. These toxic comments negatively affect mental health and create unsafe online environments.

This project presents a **Machine Learningâ€“based Toxic Comment Detection and Automatic Masking System**. The system first detects whether a comment is toxic or non-toxic using a trained machine learning model. If the comment is found to be toxic, the system automatically masks the offensive words using asterisks (`****`) so that harmful content is hidden.

This project supports:
- âœ… English language  
- âœ… Telugu language  
- âœ… Mixed (English + Telugu) code-mixed comments  

It demonstrates a real-world application of **Machine Learning + Natural Language Processing (NLP)** for online content safety.

---

## ğŸ¯ Objectives of the Project

- To automatically detect toxic and non-toxic comments  
- To build an ML-based classification system  
- To support English and Telugu mixed text  
- To correct misspelled abusive words like `idoit â†’ idiot`  
- To detect disguised abusive words like `f*ck`, `idi0t`  
- To automatically mask abusive words  
- To display prediction with confidence score  

---

## ğŸ§  How the System Works (Simple Explanation)

The project works in two main stages:

### âœ… 1. Toxicity Detection using Machine Learning
- A real-world dataset is used to train the model.
- Text is converted into numerical features using **TF-IDF Vectorizer**.
- A **Logistic Regression** model is trained for classification.
- For every new comment, the model predicts:
  - Toxic or Non-Toxic
  - Confidence probability

### âœ… 2. Automatic Toxic Word Masking
- Offensive words are:
  - Automatically extracted from toxic comments
  - Manually added in English and Telugu
  - Expanded using disguised and misspelled patterns
- If the comment is toxic:
  - Offensive words are replaced with `****`
- If the comment is non-toxic:
  - The original comment is displayed

---

## âš™ï¸ Technologies & Tools Used

- Python  
- Pandas & NumPy â€“ Data processing  
- Scikit-learn â€“ Machine Learning  
- TF-IDF Vectorizer â€“ Feature extraction  
- Logistic Regression â€“ Classification  
- Regular Expressions (Regex) â€“ Word masking  
- Jupyter Notebook â€“ Model development  
- Streamlit â€“ Web application  
- GitHub â€“ Version control & deployment  

---

## ğŸ“‚ Dataset Description

This project uses the **Jigsaw Toxic Comment Classification Dataset**.

The dataset contains the following columns:
- `comment_text`
- `toxic`
- `severe_toxic`
- `obscene`
- `threat`
- `insult`
- `identity_hate`

All these labels are combined into one binary label:
- `0 â†’ Non-Toxic`
- `1 â†’ Toxic`

The dataset is **balanced before training** to improve model performance.

---

## ğŸ” Key Features of the Project

- âœ… Machine Learning based toxic comment detection  
- âœ… Supports English and Telugu language  
- âœ… Handles misspelled abusive words  
- âœ… Handles disguised abusive word patterns  
- âœ… Automatic toxic word masking  
- âœ… Displays prediction with confidence score  
- âœ… Works in real-time as a web application  
- âœ… Industry-style detection + censorship pipeline  

---

## ğŸ§ª Sample Input & Output

### Input:
fuck you idoit, à°¨à±à°µà±à°µà± à°µà±†à°§à°µ


### Output:

Prediction: Toxic âš ï¸
Confidence: 67.84 %
Masked Output: **** you *****, à°¨à±à°µà±à°µà± ****



---

## ğŸ“ Project Folder Structure


toxic-comment-masking/
â”œâ”€â”€ app.py

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ README.md

â”œâ”€â”€ train.csv

â”œâ”€â”€README.md

â””â”€â”€ model/

  â”œâ”€â”€ toxic_model.pkl
  
  â””â”€â”€ final_bad_words.pkl



---

## â–¶ï¸ How to Run the Project Locally

### âœ… Step 1: Install Required Libraries
pip install -r requirements.txt


### âœ… Step 2: Run the Web App
streamlit run app.py


### âœ… Step 3: Open the Browser
A local link will open automatically:
http://localhost:8501


---

## ğŸŒ Live Deployment (If Deployed on Streamlit Cloud)

Once deployed, the project will be available at:
[https://your-project-name.streamlit.app](https://toxic-comment-masking.streamlit.app/)


This link can be shared with:
- Professors
- Friends
- Recruiters

---

## ğŸ“ Academic Importance of This Project

This project:
- Uses a real-world dataset  
- Implements Machine Learning classification  
- Demonstrates NLP preprocessing  
- Combines ML with rule-based masking  
- Solves a real social media safety problem  

It is suitable for:
- âœ… Final Year Project  
- âœ… Mini Project  
- âœ… Machine Learning Lab  
- âœ… NLP Project Demonstration  

---

## ğŸš€ Future Enhancements

- Add Deep Learning models like **LSTM / BERT**
- Support more Indian languages  
- Integrate with live social media APIs  
- Deploy as a mobile application  
- Add image and video toxic content detection  

---

## âœ… Final Conclusion

This project successfully demonstrates how **Machine Learning and Natural Language Processing can be used together to automatically detect and mask toxic comments**. It provides a complete end-to-end solution from data preprocessing to live web deployment.

---

## ğŸ‘¤ Author

**Name:** Viraj  
**Project Type:** Machine Learning & NLP  
**Year:** 2025
---
