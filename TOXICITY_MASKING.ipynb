{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import All Required Libraries\n",
        "*This section loads all essential libraries for data processing, text cleaning, machine learning, visualization, and model evaluation.*\n"
      ],
      "metadata": {
        "id": "BNN8H7bVWz_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnVRVyXsWC95",
        "outputId": "fd9424ca-bded-44c9-c7a7-d9238cacb9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All libraries loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from collections import Counter\n",
        "import joblib\n",
        "\n",
        "print(\"âœ… All libraries loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0EBIMxBJaSQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load the Jigsaw Toxic Comment Dataset\n",
        "*We load a real-world dataset that contains labeled toxic and non-toxic comments. This dataset is used to train our machine learning model.*\n"
      ],
      "metadata": {
        "id": "ge46X5uqW9JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/train.csv\"   # change to \"train.csv\" if running locally\n",
        "\n",
        "raw_dataset = pd.read_csv(dataset_path, engine='python', on_bad_lines='skip')\n",
        "\n",
        "toxic_label_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "raw_dataset[\"toxicity_label\"] = (raw_dataset[toxic_label_columns].sum(axis=1) > 0).astype(int)\n",
        "\n",
        "dataset = raw_dataset[[\"comment_text\", \"toxicity_label\"]]\n",
        "dataset.columns = [\"comment_text\", \"toxicity_label\"]\n",
        "\n",
        "print(dataset.head())\n",
        "print(\"\\nLabel Distribution:\")\n",
        "print(dataset[\"toxicity_label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGFlBfHjXAV7",
        "outputId": "0abd399a-b612-4a3d-a5e2-7b5eacdb7c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        comment_text  toxicity_label\n",
            "0  Explanation\\nWhy the edits made under my usern...               0\n",
            "1  D'aww! He matches this background colour I'm s...               0\n",
            "2  Hey man, I'm really not trying to edit war. It...               0\n",
            "3  \"\\nMore\\nI can't make any real suggestions on ...               0\n",
            "4  You, sir, are my hero. Any chance you remember...               0\n",
            "\n",
            "Label Distribution:\n",
            "toxicity_label\n",
            "0    143346\n",
            "1     16225\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Balance the Dataset\n",
        "*The dataset contains more non-toxic comments than toxic ones. We balance the data so the model learns both classes equally and avoids bias.*\n"
      ],
      "metadata": {
        "id": "oSbY0jQtYNwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_comments = dataset[dataset[\"toxicity_label\"] == 1]\n",
        "non_toxic_comments = dataset[dataset[\"toxicity_label\"] == 0]\n",
        "\n",
        "toxic_count = len(toxic_comments)\n",
        "\n",
        "balanced_dataset = pd.concat([\n",
        "    toxic_comments,\n",
        "    non_toxic_comments.sample(toxic_count, random_state=42)\n",
        "])\n",
        "\n",
        "balanced_dataset = balanced_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"âœ… Balanced Dataset Distribution:\")\n",
        "print(balanced_dataset[\"toxicity_label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sGdFkGDYPqK",
        "outputId": "9ae29cff-881b-4ff3-c124-a091a60768fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Balanced Dataset Distribution:\n",
            "toxicity_label\n",
            "1    16225\n",
            "0    16225\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Text Preprocessing Function\n",
        "*This function removes URLs, special characters, emojis, and converts the text into a clean format suitable for machine learning.*\n"
      ],
      "metadata": {
        "id": "CiSTBrrTYRSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_comment(comment_text):\n",
        "    comment_text = comment_text.lower()\n",
        "    comment_text = re.sub(r\"http\\S+|@\\w+|#\\w+\", \"\", comment_text)\n",
        "    comment_text = re.sub(r\"[^\\u0C00-\\u0C7Fa-zA-Z\\s]\", \"\", comment_text)\n",
        "    comment_text = re.sub(r\"\\s+\", \" \", comment_text).strip()\n",
        "    return comment_text\n"
      ],
      "metadata": {
        "id": "cxyPFv0ZYSLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Normalize Common Misspellings\n",
        "*Users intentionally misspell abusive words (e.g., idoit â†’ idiot). This step improves detection accuracy.*\n"
      ],
      "metadata": {
        "id": "jW5rIQgqYUvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COMMON_MISSPELLING_MAP = {\n",
        "    \"idoit\": \"idiot\",\n",
        "    \"stupit\": \"stupid\",\n",
        "    \"fuk\": \"fuck\",\n",
        "    \"fck\": \"fuck\",\n",
        "    \"bich\": \"bitch\",\n",
        "    \"asshloe\": \"asshole\"\n",
        "}\n",
        "\n",
        "def normalize_slang_words(clean_text):\n",
        "    words = clean_text.split()\n",
        "    corrected_words = [COMMON_MISSPELLING_MAP.get(word, word) for word in words]\n",
        "    return \" \".join(corrected_words)\n"
      ],
      "metadata": {
        "id": "L2OS1FENYVaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Apply Preprocessing to the Entire Dataset\n",
        "*We clean and normalize every comment before training the model.*\n"
      ],
      "metadata": {
        "id": "Met-WTOLYXD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_dataset[\"cleaned_comment\"] = balanced_dataset[\"comment_text\"].apply(preprocess_comment)\n",
        "balanced_dataset[\"cleaned_comment\"] = balanced_dataset[\"cleaned_comment\"].apply(normalize_slang_words)\n",
        "\n",
        "balanced_dataset.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "KdFq3pQ0YX_J",
        "outputId": "c432a44b-b037-4dc2-800d-03b596b71cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        comment_text  toxicity_label  \\\n",
              "0      You are an old cougar! You are an old cougar!               1   \n",
              "1            I'm scared\\nbrrrr.... i'm gonna die now               0   \n",
              "2  Okay, so anal sex is as widely unaccepted and ...               1   \n",
              "3  shut up you cunt\\nWWWWWWWWWWWWWWWWWWWWWWWWWWWW...               1   \n",
              "4  You arrogant administrator homosexual bastards...               1   \n",
              "\n",
              "                                     cleaned_comment  \n",
              "0        you are an old cougar you are an old cougar  \n",
              "1                   im scared brrrr im gonna die now  \n",
              "2  okay so anal sex is as widely unaccepted and d...  \n",
              "3  shut up you cunt wwwwwwwwwwwwwwwwwwwwwwwwwwwww...  \n",
              "4  you arrogant administrator homosexual bastards...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-581c831b-6ba1-4904-ac6a-7b298c07f484\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxicity_label</th>\n",
              "      <th>cleaned_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You are an old cougar! You are an old cougar!</td>\n",
              "      <td>1</td>\n",
              "      <td>you are an old cougar you are an old cougar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm scared\\nbrrrr.... i'm gonna die now</td>\n",
              "      <td>0</td>\n",
              "      <td>im scared brrrr im gonna die now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Okay, so anal sex is as widely unaccepted and ...</td>\n",
              "      <td>1</td>\n",
              "      <td>okay so anal sex is as widely unaccepted and d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>shut up you cunt\\nWWWWWWWWWWWWWWWWWWWWWWWWWWWW...</td>\n",
              "      <td>1</td>\n",
              "      <td>shut up you cunt wwwwwwwwwwwwwwwwwwwwwwwwwwwww...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You arrogant administrator homosexual bastards...</td>\n",
              "      <td>1</td>\n",
              "      <td>you arrogant administrator homosexual bastards...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-581c831b-6ba1-4904-ac6a-7b298c07f484')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-581c831b-6ba1-4904-ac6a-7b298c07f484 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-581c831b-6ba1-4904-ac6a-7b298c07f484');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7c0ff0f9-6c48-44e0-9e40-70b1c912d937\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c0ff0f9-6c48-44e0-9e40-70b1c912d937')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7c0ff0f9-6c48-44e0-9e40-70b1c912d937 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_dataset",
              "summary": "{\n  \"name\": \"balanced_dataset\",\n  \"rows\": 32450,\n  \"fields\": [\n    {\n      \"column\": \"comment_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32450,\n        \"samples\": [\n          \"\\\"\\n\\n WP:DYK \\n\\nThank you for creating the Philip I, Duke of Pomerania article. If you create such an extensive article, you may want to consider adding inline references (per WP:CITE) and nominating it at T:TDYK for front page exposure. | talk  \\\"\",\n          \"Missing info \\n\\nWhat about the fact that they have become far left communist marxists, way out of touch with mainstream america?  (There are numerous reliable sources.)\",\n          \"\\\"\\n Your submission at Articles for creation \\n Moses Bowness, Victorian Photographer 1834-8194, which you submitted to Articles for creation, has been created. \\n Please continue making quality contributions to Wikipedia. Note that because you are a logged-in user, you can create articles yourself, and don't have to post a request.\\n If you would like to help us improve this process, please consider \\nThank you for helping Wikipedia! \\u00a0\\u25ba\\u00a0 \\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"toxicity_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32284,\n        \"samples\": [\n          \"fuck you fdfdf fuck you faggot\",\n          \"please do not delete websites without knowing what you are doing this is a big game its just not world wide yet ive seen many articles like this on wikipedia i dont see how ours is diffrent until then fick dich\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Split Dataset into Train & Test Sets\n",
        "*We divide our dataset into training and testing sets to evaluate how well the model performs on unseen data.*\n"
      ],
      "metadata": {
        "id": "moB6Dd2eYbAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_text = balanced_dataset[\"cleaned_comment\"]\n",
        "target_labels = balanced_dataset[\"toxicity_label\"]\n",
        "\n",
        "training_text, testing_text, training_labels, testing_labels = train_test_split(\n",
        "    feature_text, target_labels, test_size=0.2, random_state=42, stratify=target_labels\n",
        ")\n"
      ],
      "metadata": {
        "id": "Yee3_trIYcRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Train Machine Learning Model (TF-IDF + Logistic Regression)\n",
        "*TF-IDF converts text into numerical features and Logistic Regression is used to classify comments as toxic or non-toxic.*\n"
      ],
      "metadata": {
        "id": "MoHSrcH1YeL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toxicity_detection_pipeline = Pipeline([\n",
        "    (\"tfidf_vectorizer\", TfidfVectorizer(\n",
        "        ngram_range=(1, 3),\n",
        "        max_features=15000,\n",
        "        min_df=3,\n",
        "        max_df=0.9,\n",
        "        sublinear_tf=True\n",
        "    )),\n",
        "    (\"logistic_classifier\", LogisticRegression(\n",
        "        max_iter=2000,\n",
        "        class_weight=\"balanced\",\n",
        "        solver=\"lbfgs\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "toxicity_detection_pipeline.fit(training_text, training_labels)\n",
        "\n",
        "predicted_labels = toxicity_detection_pipeline.predict(testing_text)\n",
        "\n",
        "print(classification_report(testing_labels, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM0_DWzVYfR5",
        "outputId": "5d805a67-e2b3-4c8b-e0d1-6bc5acd3ffa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89      3245\n",
            "           1       0.91      0.86      0.88      3245\n",
            "\n",
            "    accuracy                           0.89      6490\n",
            "   macro avg       0.89      0.89      0.89      6490\n",
            "weighted avg       0.89      0.89      0.89      6490\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Initial Toxicity Test Before Masking\n",
        "*We test the trained model using a custom comment to verify that toxicity detection is working correctly.*\n"
      ],
      "metadata": {
        "id": "eseJlnBMYi6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_comment = \"fuck you idoit\"\n",
        "\n",
        "cleaned_input_comment = normalize_slang_words(preprocess_comment(input_comment))\n",
        "\n",
        "prediction_probability = toxicity_detection_pipeline.predict_proba([cleaned_input_comment])[0][1]\n",
        "prediction_label = toxicity_detection_pipeline.predict([cleaned_input_comment])[0]\n",
        "\n",
        "print(\"Prediction:\", \"Toxic\" if prediction_label == 1 else \"Non-Toxic\")\n",
        "print(\"Score:\", round(prediction_probability * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lpT9xqyYjs5",
        "outputId": "8a01e2eb-86e5-4ab9-bf0d-a66f9a6e7d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Toxic\n",
            "Score: 99.99 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Auto-Extract Offensive Words From Toxic Comments\n",
        "*We automatically extract the most commonly used abusive words from real toxic comments in the dataset.*\n"
      ],
      "metadata": {
        "id": "5kxAXmOFYla6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_top_toxic_words_from_dataset(balanced_dataset, top_n=300):\n",
        "    toxic_sentences = balanced_dataset[balanced_dataset[\"toxicity_label\"] == 1][\"cleaned_comment\"]\n",
        "    combined_words = \" \".join(toxic_sentences).split()\n",
        "    filtered_words = [word for word in combined_words if len(word) > 2]\n",
        "    word_counter = Counter(filtered_words)\n",
        "    return [word for word, count in word_counter.most_common(top_n)]\n",
        "\n",
        "auto_extracted_bad_words = extract_top_toxic_words_from_dataset(balanced_dataset)\n"
      ],
      "metadata": {
        "id": "rj97gqvMYomq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Add Extra English & Telugu Offensive Words\n",
        "*To ensure complete coverage, we manually add commonly known abusive words that may not appear frequently in the dataset.*\n"
      ],
      "metadata": {
        "id": "k9OxWk61YpWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_offensive_words = [\n",
        "    \"slut\",\"whore\",\"dick\",\"cock\",\"pussy\",\"cunt\",\"hoe\",\n",
        "    \"retard\",\"douche\",\"prick\",\"motherfucker\",\"mf\",\n",
        "    \"asswipe\",\"jerk\",\"fucktard\"\n",
        "]\n",
        "\n",
        "telugu_offensive_words = [\n",
        "    \"à°¦à±Šà°‚à°—\", \"à°®à±‚à°°à±à°–à±à°¡à±\", \"à°¨à±€à°šà±à°¡à±\", \"à°²à°‚à°œ\", \"à°¦à±†à°‚à°—à±\",\n",
        "    \"à°ªà°¿à°šà±à°šà±‹à°¡à±\", \"à°…à°¸à°¹à±à°¯à°‚\", \"à°šà±†à°¤à±à°¤à±‹à°¡à±\", \"à°¬à±à°¦à±à°§à°¿à°²à±‡à°¨à°¿\",\n",
        "    \"à°¦à±à°°à±à°®à°¾à°°à±à°—à±à°¡à±\",\"à°µà±†à°§à°µ\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "be4wcov_Yq-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Generate Disguised / Leet Variants of Offensive Words\n",
        "*Users hide abusive words using symbols and numbers (f*ck, idi0t). This function detects those variations.*\n"
      ],
      "metadata": {
        "id": "JLILXWn9YtmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_disguised_variants(base_word):\n",
        "    variants = set()\n",
        "    variants.add(base_word)\n",
        "\n",
        "    leet_replacements = {\n",
        "        \"a\": [\"@\", \"4\"],\n",
        "        \"i\": [\"1\", \"!\"],\n",
        "        \"e\": [\"3\"],\n",
        "        \"o\": [\"0\"],\n",
        "        \"s\": [\"$\", \"5\"],\n",
        "        \"t\": [\"7\"]\n",
        "    }\n",
        "\n",
        "    for index, character in enumerate(base_word):\n",
        "        if character in leet_replacements:\n",
        "            for replacement in leet_replacements[character]:\n",
        "                variants.add(base_word[:index] + replacement + base_word[index+1:])\n",
        "\n",
        "    variants.add(base_word + base_word[-1])\n",
        "    variants.add(\".\".join(base_word))\n",
        "\n",
        "    if len(base_word) > 3:\n",
        "        variants.add(base_word[0] + \"*\"*(len(base_word)-2) + base_word[-1])\n",
        "\n",
        "    return variants\n"
      ],
      "metadata": {
        "id": "0cvJs45aYuRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Build the Final Industry-Grade Offensive Word Set\n",
        "*We combine dataset-extracted words, English and Telugu lists, and disguised variants to form a powerful masking dictionary.*\n"
      ],
      "metadata": {
        "id": "uMI0CsM4Yvzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_offensive_word_list = set()\n",
        "\n",
        "for word in auto_extracted_bad_words:\n",
        "    final_offensive_word_list.add(word)\n",
        "    final_offensive_word_list.update(generate_disguised_variants(word))\n",
        "\n",
        "for word in english_offensive_words:\n",
        "    final_offensive_word_list.add(word)\n",
        "    final_offensive_word_list.update(generate_disguised_variants(word))\n",
        "\n",
        "for word in telugu_offensive_words:\n",
        "    final_offensive_word_list.add(word)\n",
        "\n",
        "final_offensive_word_list = set([word.lower() for word in final_offensive_word_list if isinstance(word, str)])\n",
        "\n",
        "print(\"âœ… Total Offensive Patterns:\", len(final_offensive_word_list))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se2_iXjBYx8J",
        "outputId": "42f4df66-08c9-4ee3-b9dd-7452ed4d31d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Total Offensive Patterns: 2159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Precompile Regex Patterns for Fast Masking\n",
        "*Precompiling regex patterns improves the performance of real-time masking.*\n"
      ],
      "metadata": {
        "id": "lbVELTafYzux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_masking_patterns = []\n",
        "\n",
        "for word in final_offensive_word_list:\n",
        "    if len(word) <= 2:\n",
        "        continue\n",
        "    compiled_masking_patterns.append(re.compile(re.escape(word), flags=re.IGNORECASE))\n"
      ],
      "metadata": {
        "id": "5YYD9IvsY0ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. Final Advanced Masking Function\n",
        "*This function replaces every detected abusive word with asterisks of equal length.*\n"
      ],
      "metadata": {
        "id": "2epPakWCY2sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def advanced_toxic_word_masking(original_text):\n",
        "    masked_text = original_text\n",
        "    for pattern in compiled_masking_patterns:\n",
        "        masked_text = pattern.sub(lambda match: \"*\" * len(match.group(0)), masked_text)\n",
        "    return masked_text\n"
      ],
      "metadata": {
        "id": "X6x1siNuY3vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16. Final Detection + Masking Pipeline\n",
        "*This function combines machine learning toxicity detection and rule-based masking into one complete pipeline.*\n"
      ],
      "metadata": {
        "id": "WFbX80_kY49h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_mask_toxicity(input_text):\n",
        "    cleaned_text = normalize_slang_words(preprocess_comment(input_text))\n",
        "\n",
        "    prediction_label = toxicity_detection_pipeline.predict([cleaned_text])[0]\n",
        "    prediction_probability = toxicity_detection_pipeline.predict_proba([cleaned_text])[0][1]\n",
        "\n",
        "    if prediction_label == 1:\n",
        "        masked_output_text = advanced_toxic_word_masking(input_text)\n",
        "        final_label = \"Toxic âš ï¸\"\n",
        "    else:\n",
        "        masked_output_text = input_text\n",
        "        final_label = \"Non-Toxic âœ…\"\n",
        "\n",
        "    return final_label, round(prediction_probability * 100, 2), masked_output_text\n"
      ],
      "metadata": {
        "id": "0WtQULUvY6AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 17. Final User Input Test Cell (Live Project Demo)\n",
        "*This is the final demo cell to show how the system detects toxicity and applies masking in real time.*\n"
      ],
      "metadata": {
        "id": "kXeqf352Y7bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo_input_comment = \"fuck that idoit, à°¨à±à°µà±à°µà± à°µà±†à°§à°µ\"\n",
        "\n",
        "demo_label, demo_score, demo_masked_output = detect_and_mask_toxicity(demo_input_comment)\n",
        "\n",
        "print(\"\\nðŸ›¡ï¸ FINAL INDUSTRY-GRADE PROJECT OUTPUT\")\n",
        "print(\"=\"*60)\n",
        "print(\"Original Comment :\", demo_input_comment)\n",
        "print(\"Prediction       :\", demo_label)\n",
        "print(\"Toxicity Score   :\", demo_score, \"%\")\n",
        "print(\"Masked Output    :\", demo_masked_output)\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzDX6IIfY8HR",
        "outputId": "91bfee25-da0b-42a9-ea6f-b3f6fd407a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ›¡ï¸ FINAL INDUSTRY-GRADE PROJECT OUTPUT\n",
            "============================================================\n",
            "Original Comment : fuck that idoit, à°¨à±à°µà±à°µà± à°µà±†à°§à°µ\n",
            "Prediction       : Toxic âš ï¸\n",
            "Toxicity Score   : 100.0 %\n",
            "Masked Output    : **** **** idoit, à°¨à±à°µà±à°µà± ****\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STREAMLIT APP\n"
      ],
      "metadata": {
        "id": "ovNzaZB3be-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model folder\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "\n",
        "# Save trained ML model\n",
        "joblib.dump(toxicity_detection_pipeline, \"model/toxic_model.pkl\")\n",
        "\n",
        "# Save offensive word list\n",
        "joblib.dump(list(final_offensive_word_list), \"model/final_bad_words.pkl\")\n",
        "\n",
        "print(\"âœ… Model and masking data saved successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bunK7s4MbjC-",
        "outputId": "848cdb4c-8268-48d5-e241-c2d04998773b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model and masking data saved successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INSTALLING STREAMLIT"
      ],
      "metadata": {
        "id": "k8G3l4USbwVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vqLt8oWbple",
        "outputId": "a1845453-83dc-4af4-93d5-7c9be62938a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.52.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vzn__Y_6b0wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6VEXNJEfq_Q",
        "outputId": "dd927f22-4a35-4415-c5d3-6730cd874dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"36fIO9OQVeboOfNIXmL3lNcGeTG_6s2oRrfvShNFLW8u9vebR\")\n"
      ],
      "metadata": {
        "id": "2N1VudDZhk2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "print(\"âœ… Your Public Web App Link:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7rGeWdfhwpe",
        "outputId": "96d28269-02e6-48ec-c6e6-e0ebfea6b8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Your Public Web App Link: NgrokTunnel: \"https://ryleigh-claimable-osmotically.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DY_pqnLylN2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "gydA0-j6fx05"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}